<story-context id="3-1-openai-vision-api-integration" v="1.0">
  <metadata>
    <epicId>3</epicId>
    <storyId>3.1</storyId>
    <title>OpenAI Vision API Integration</title>
    <status>drafted</status>
    <generatedAt>2025-12-01</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/3-1-openai-vision-api-integration.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>system</asA>
    <iWant>to send images to OpenAI Vision API and receive structured metadata</iWant>
    <soThat>we can automatically generate titles, keywords, and categories for Adobe Stock</soThat>
    <tasks>
      <task id="1">Add request timeout configuration to app.config.ts (OPENAI_TIMEOUT_MS, default 30000)</task>
      <task id="2">Implement AbortController-based timeout in MetadataService.generateMetadata()</task>
      <task id="3">Create Zod schema for RawAIMetadata validation</task>
      <task id="4">Enhance parseAIResponse() with Zod validation</task>
      <task id="5">Add explicit error classification logging for retry decisions</task>
      <task id="6">Add duration logging for individual API calls</task>
      <task id="7">Create unit tests for timeout scenarios (mock abort signal)</task>
      <task id="8">Create unit tests for Zod validation (malformed responses)</task>
      <task id="9">Create unit tests for error classification</task>
      <task id="10">Verify &lt;5 second average processing time target</task>
      <task id="11">Run full test suite and verify no regressions</task>
      <task id="12">Update sprint-status.yaml to "drafted"</task>
    </tasks>
  </story>

  <acceptanceCriteria>
    <ac id="AC1" title="OpenAI Model Configuration">
      <given>the metadata service is initialized</given>
      <when>an image is processed</when>
      <then>the OpenAI API should be called with: Model: gpt-5-mini (configurable via environment), Temperature: 0.3 (accuracy over creativity), Max tokens: 500 (sufficient for metadata)</then>
    </ac>
    <ac id="AC2" title="Image Detail Configuration">
      <given>an image URL is sent to OpenAI</given>
      <when>the Vision API request is made</when>
      <then>the image detail level should be "low" (reduces cost, sufficient for metadata generation)</then>
    </ac>
    <ac id="AC3" title="Structured Prompt for JSON Response">
      <given>the AI prompt is sent</given>
      <when>OpenAI processes the image</when>
      <then>the response should be parsed into: interface ImageMetadata { title: string; keywords: string[]; category: number; }</then>
    </ac>
    <ac id="AC4" title="API Timeout Handling">
      <given>an OpenAI API call is in progress</given>
      <when>the request exceeds 30 seconds</when>
      <then>the call should timeout and throw an ExternalServiceError</then>
    </ac>
    <ac id="AC5" title="Response Validation">
      <given>OpenAI returns a response</given>
      <when>parsing the JSON</when>
      <then>validation should ensure: title field is present and non-empty string, keywords field is present and is an array, category field is present and is a number or string</then>
    </ac>
    <ac id="AC6" title="Error Classification">
      <given>an OpenAI API error occurs</given>
      <when>the error is handled</when>
      <then>errors should be classified: Retry on: 429 (rate limit), 5xx (server errors), network timeouts. Do NOT retry on: 401 (auth), 400 (validation)</then>
    </ac>
    <ac id="AC7" title="API Cost Tracking">
      <given>a successful OpenAI call</given>
      <when>metadata is generated</when>
      <then>the cost should be tracked via metrics (~$0.002 per image for gpt-5-mini)</then>
    </ac>
    <ac id="AC8" title="Processing Duration Target">
      <given>an image URL is submitted</given>
      <when>metadata generation completes successfully</when>
      <then>the average duration should be &lt;5 seconds</then>
    </ac>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/epics.md</path>
        <title>Epic Breakdown</title>
        <section>Epic 3: AI Metadata Generation Engine - Story 3.1</section>
        <snippet>Goal: Implement intelligence layer analyzing images for Adobe Stock-compliant metadata using OpenAI Vision API. Refactor existing src/openai.ts into services, add response validation, implement exponential backoff.</snippet>
      </doc>
      <doc>
        <path>docs/stories/3-1-openai-vision-api-integration.md</path>
        <title>Story 3.1 Definition</title>
        <section>Full Story</section>
        <snippet>Details 8 ACs, 12 tasks, technical notes on existing MetadataService implementation and required enhancements for timeout, Zod validation, error classification.</snippet>
      </doc>
      <doc>
        <path>docs/ARCHITECTURE_REFACTORING_GUIDE.md</path>
        <title>Architecture Refactoring Guide</title>
        <section>Service Layer Patterns</section>
        <snippet>Established patterns: Service singleton via container, DI for testability, typed errors (ExternalServiceError), withRetry wrapper for resilience.</snippet>
      </doc>
      <doc>
        <path>docs/sprint-status.yaml</path>
        <title>Sprint Status</title>
        <section>Sprint 3 Planning</section>
        <snippet>Sprint 3 goal: AI-powered metadata generation. Story 3.1 targets Day 1-2. Existing foundation: MetadataService, PROMPT_TEXT, Metadata models.</snippet>
      </doc>
    </docs>

    <code>
      <artifact>
        <path>src/services/metadata.service.ts</path>
        <kind>service</kind>
        <symbol>MetadataService</symbol>
        <lines>1-171</lines>
        <reason>PRIMARY TARGET: Existing OpenAI integration with generateMetadata(), parseAIResponse(), validateConnection(). Needs timeout via AbortController, enhanced validation with Zod.</reason>
      </artifact>
      <artifact>
        <path>src/config/app.config.ts</path>
        <kind>config</kind>
        <symbol>ConfigService</symbol>
        <lines>1-88</lines>
        <reason>Needs OPENAI_TIMEOUT_MS env var added to Zod schema and openai getter section.</reason>
      </artifact>
      <artifact>
        <path>src/models/metadata.model.ts</path>
        <kind>model</kind>
        <symbol>RawAIMetadata, Metadata, ProcessingResult</symbol>
        <lines>1-207</lines>
        <reason>RawAIMetadata interface (title: string, keywords: string[], category: number|string) - needs Zod schema for validation.</reason>
      </artifact>
      <artifact>
        <path>src/models/errors.ts</path>
        <kind>model</kind>
        <symbol>ExternalServiceError, AppError</symbol>
        <lines>114-126</lines>
        <reason>ExternalServiceError used for OpenAI failures. Include service context for error classification.</reason>
      </artifact>
      <artifact>
        <path>src/utils/retry.ts</path>
        <kind>utility</kind>
        <symbol>withRetry, RetryOptions, isRetryableError</symbol>
        <lines>1-313</lines>
        <reason>Existing retry logic with exponential backoff. Already handles 429, 5xx errors. Used in MetadataService.</reason>
      </artifact>
      <artifact>
        <path>src/utils/metrics.ts</path>
        <kind>utility</kind>
        <symbol>recordOpenAICall, recordOpenAIFailure</symbol>
        <reason>Metrics recording for OpenAI calls (duration, cost). Already integrated in MetadataService.</reason>
      </artifact>
      <artifact>
        <path>src/prompt-text.ts</path>
        <kind>config</kind>
        <symbol>PROMPT_TEXT</symbol>
        <lines>1-28</lines>
        <reason>Current prompt requesting JSON with title, keywords, category. Note: requests 25 keywords, story says 30-50 (Story 3.3 addresses this).</reason>
      </artifact>
      <artifact>
        <path>tests/metadata.service.test.ts</path>
        <kind>test</kind>
        <symbol>MetadataService tests</symbol>
        <lines>1-351</lines>
        <reason>Existing 15+ tests covering generateMetadata, parseAIResponse, validateConnection. Need to add timeout tests, Zod validation tests, error classification tests.</reason>
      </artifact>
    </code>

    <dependencies>
      <runtime>
        <package name="openai" version="^6.8.1">OpenAI SDK - chat.completions.create() with vision</package>
        <package name="zod" version="^4.1.12">Schema validation - ALREADY INSTALLED, use for RawAIMetadata validation</package>
        <package name="pino" version="^10.1.0">Structured logging - logger utility</package>
        <package name="prom-client" version="^15.1.3">Prometheus metrics - recordOpenAICall, recordOpenAIFailure</package>
      </runtime>
      <dev>
        <package name="vitest" version="^4.0.8">Test framework</package>
        <package name="supertest" version="^7.1.4">API testing</package>
      </dev>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint type="pattern">Use existing service singleton pattern - MetadataService already follows this</constraint>
    <constraint type="pattern">Use ExternalServiceError for all OpenAI failures (502 Bad Gateway)</constraint>
    <constraint type="pattern">Use withRetry wrapper for resilience - already integrated</constraint>
    <constraint type="pattern">Use structured logging with Pino - use logger.info/error/warn</constraint>
    <constraint type="pattern">Use config service for all environment variables - config.openai.*</constraint>
    <constraint type="testing">All new code must have unit tests - use existing test patterns in tests/metadata.service.test.ts</constraint>
    <constraint type="testing">Mock OpenAI SDK using vi.mock('openai') pattern</constraint>
    <constraint type="testing">Mock config using vi.mock('../src/config/app.config')</constraint>
    <constraint type="performance">API calls must complete in &lt;5 seconds average</constraint>
    <constraint type="cost">Use detail: "low" for images (~$0.002 per call)</constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>MetadataService.generateMetadata</name>
      <kind>method</kind>
      <signature>async generateMetadata(imageUrl: string): Promise&lt;RawAIMetadata&gt;</signature>
      <path>src/services/metadata.service.ts:41-105</path>
      <notes>Primary method to enhance with AbortController timeout</notes>
    </interface>
    <interface>
      <name>MetadataService.parseAIResponse</name>
      <kind>private-method</kind>
      <signature>private parseAIResponse(responseText: string): RawAIMetadata</signature>
      <path>src/services/metadata.service.ts:118-149</path>
      <notes>Enhance with Zod validation instead of manual field checking</notes>
    </interface>
    <interface>
      <name>OpenAI chat.completions.create</name>
      <kind>external-api</kind>
      <signature>openai.chat.completions.create({ model, messages, max_completion_tokens, temperature, signal? })</signature>
      <notes>OpenAI SDK supports AbortSignal via signal parameter for timeout</notes>
    </interface>
    <interface>
      <name>RawAIMetadata</name>
      <kind>interface</kind>
      <signature>interface RawAIMetadata { title: string; keywords: string[]; category: number | string; }</signature>
      <path>src/models/metadata.model.ts:202-206</path>
      <notes>Create matching Zod schema: z.object({ title: z.string().min(1), keywords: z.union([z.array(z.string()), z.string()]), category: z.union([z.number(), z.string()]) })</notes>
    </interface>
    <interface>
      <name>config.openai</name>
      <kind>config-getter</kind>
      <signature>config.openai: { apiKey, model, maxTokens, temperature, timeoutMs? }</signature>
      <path>src/config/app.config.ts:62-69</path>
      <notes>Add timeoutMs field (default 30000)</notes>
    </interface>
  </interfaces>

  <tests>
    <standards>
      Tests use Vitest framework with describe/it/expect pattern. Mock external dependencies (OpenAI, config) using vi.mock(). 
      Use beforeEach for setup, afterEach for cleanup. Follow existing patterns in tests/metadata.service.test.ts.
      Run tests with: npm test (vitest run) or npm run test:watch (vitest).
      Current test count: 463 tests passing (including Epic 1 &amp; 2).
    </standards>
    <locations>
      <location>tests/metadata.service.test.ts</location>
      <location>tests/*.test.ts</location>
    </locations>
    <ideas>
      <idea acRef="AC4">Test timeout: Mock AbortController abort, verify ExternalServiceError thrown with timeout context</idea>
      <idea acRef="AC4">Test timeout edge case: Request completes just before timeout</idea>
      <idea acRef="AC5">Test Zod validation success: Valid JSON with all required fields</idea>
      <idea acRef="AC5">Test Zod validation failure: Missing title field</idea>
      <idea acRef="AC5">Test Zod validation failure: Empty keywords array</idea>
      <idea acRef="AC5">Test Zod validation: Keywords as comma-separated string (transformed to array)</idea>
      <idea acRef="AC5">Test Zod validation: Category as string vs number</idea>
      <idea acRef="AC6">Test error classification: 429 triggers retry (via withRetry mock)</idea>
      <idea acRef="AC6">Test error classification: 500 triggers retry</idea>
      <idea acRef="AC6">Test error classification: 401 does NOT retry</idea>
      <idea acRef="AC6">Test error classification: 400 does NOT retry</idea>
      <idea acRef="AC6">Test logging of error classification decision</idea>
      <idea acRef="AC7">Test metrics: Verify recordOpenAICall called with duration and cost</idea>
      <idea acRef="AC8">Test performance: Verify API call completes in reasonable time (mock fast response)</idea>
    </ideas>
  </tests>
</story-context>

